{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ajout des nouvelles données.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MyyFu145pKkI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ce notebook a pour but d'ajouter des colonnes à X_train ou X_test à partir de fichiers de données déjà nettoyés."
      ]
    },
    {
      "metadata": {
        "id": "WnA4vNKupeMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import isnan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EIAeceOIvNQA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importation des fichiers originaux"
      ]
    },
    {
      "metadata": {
        "id": "OwZfgrQjpgeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_url = \"https://raw.githubusercontent.com/BenjaminBcmp/DataChallengeGenerali/master/data/X_train.csv\"\n",
        "X_test_url = \"https://raw.githubusercontent.com/BenjaminBcmp/DataChallengeGenerali/master/data/X_test.csv\"\n",
        "y_train_url = \"https://raw.githubusercontent.com/BenjaminBcmp/DataChallengeGenerali/master/data/y_train_saegPGl.csv\"\n",
        "X_train = pd.read_csv(X_train_url, header=0, index_col=0)\n",
        "X_test = pd.read_csv(X_test_url, header=0, index_col=0)\n",
        "y_train = pd.read_csv(y_train_url, header=0, index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pg9afZVVHdG4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Données manquantes pour train et test :"
      ]
    },
    {
      "metadata": {
        "id": "NZcnF6duHZAn",
        "colab_type": "code",
        "outputId": "801af4e4-689b-4b8d-a94a-e20c64d23e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "for col in X_train.columns:\n",
        "    print(col, np.sum(X_train[col].isna()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Identifiant 0\n",
            "ft_2_categ 0\n",
            "EXPO 0\n",
            "ft_4_categ 0\n",
            "ft_5_categ 0\n",
            "ft_6_categ 0\n",
            "ft_7_categ 0\n",
            "ft_8_categ 0\n",
            "ft_9_categ 0\n",
            "ft_10_categ 0\n",
            "ft_11_categ 0\n",
            "ft_12_categ 0\n",
            "ft_13_categ 0\n",
            "ft_14_categ 0\n",
            "ft_15_categ 0\n",
            "ft_16_categ 0\n",
            "ft_17_categ 0\n",
            "ft_18_categ 0\n",
            "ft_19_categ 0\n",
            "superficief 119\n",
            "ft_21_categ 0\n",
            "ft_22_categ 1236\n",
            "ft_23_categ 0\n",
            "ft_24_categ 0\n",
            "Insee 115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VoN5_8RlH2TT",
        "colab_type": "code",
        "outputId": "edaf2dce-54dd-4fb5-e5aa-b8e19fda0dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "for col in X_test.columns:\n",
        "    print(col, np.sum(X_test[col].isna()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Identifiant 0\n",
            "ft_2_categ 0\n",
            "EXPO 0\n",
            "ft_4_categ 0\n",
            "ft_5_categ 0\n",
            "ft_6_categ 0\n",
            "ft_7_categ 0\n",
            "ft_8_categ 0\n",
            "ft_9_categ 0\n",
            "ft_10_categ 0\n",
            "ft_11_categ 0\n",
            "ft_12_categ 0\n",
            "ft_13_categ 0\n",
            "ft_14_categ 0\n",
            "ft_15_categ 0\n",
            "ft_16_categ 0\n",
            "ft_17_categ 0\n",
            "ft_18_categ 0\n",
            "ft_19_categ 0\n",
            "superficief 42\n",
            "ft_21_categ 0\n",
            "ft_22_categ 402\n",
            "ft_23_categ 0\n",
            "ft_24_categ 0\n",
            "Insee 39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8x1Z4lFoH_sk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous allons traiter les données manquantes de `ft_22_categ` comme une nouvelle catégorie. Pour le train, nous supprimons les autres lignes où il manque des données. Pour le test, nous remplacerons les autres données manquantes (dans `superficief` ainsi que celles que nous allons rajouter) par la moyenne ou la médiane de la variable."
      ]
    },
    {
      "metadata": {
        "id": "1Z7WEtZBoXDi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Quelques fonctions pour ajouter des colonnes à notre jeu de données"
      ]
    },
    {
      "metadata": {
        "id": "YhNY2flCFn8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Données manquantes"
      ]
    },
    {
      "metadata": {
        "id": "f6AY3zQfFrdX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def is_nan(val):\n",
        "    if type(val) is float and isnan(val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def replace_missing_by_mean(col):\n",
        "    \"\"\"Données manquantes : -1\n",
        "    On les remplace par la moyenne de la colonne\"\"\"\n",
        "    moy = np.mean(col[col!=-1])\n",
        "    col[col==-1] = moy\n",
        "    return col\n",
        "\n",
        "def replace_missing_by_med(col):\n",
        "    \"\"\"Données manquantes : -1\n",
        "    On les remplace par la médiane de la colonne\"\"\"\n",
        "    moy = np.median(col[col!=-1])\n",
        "    col[col==-1] = moy\n",
        "    return col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFqwB4V2ofuF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Chômage"
      ]
    },
    {
      "metadata": {
        "id": "hCV1P9XkoWyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ajout_chomage(X, chomage):\n",
        "    \"\"\"Renvoie la colonne contenant le taux de chômage par année et code Insee\"\"\"\n",
        "    departements = np.array(chomage['Code'])\n",
        "    #On ajoute le chomage quand l'insee est spécifié, -1 sinon\n",
        "    colonne = np.array([chomage[str(annee)][departements==insee[:2]].values[0] \\\n",
        "                     if not is_nan(insee) else -1 for annee,insee in zip(X.ft_2_categ, X.Insee) ])\n",
        "    #On remplace les 0 par la moyenne du chomage\n",
        "    colonne = replace_missing_by_mean(colonne)\n",
        "    return colonne"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJMAUYzWoh-U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Revenus"
      ]
    },
    {
      "metadata": {
        "id": "8b8KB1hvxqB0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On commence par écrire une fonction qui prédit (estime) le revenu médian en 2016 (données non disponibles). On choisit de prendre la moyenne des revenus médians des deux années précédentes :"
      ]
    },
    {
      "metadata": {
        "id": "ur4RKcVawH7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pred_revenu_2016(code, revenus, revenus_dep):\n",
        "    \"\"\"Prédit le revenu médian en 2016 pour le code Insee.\n",
        "    Prédiction = moyenne des revenus médians des deux années précédentes pour le\n",
        "    code INSEE quand ils sont disponibles, sinon on utilise les revenus du \n",
        "    département\"\"\"\n",
        "    rev14, rev15 = revenus[2], revenus[3]\n",
        "    if code in np.array(rev14.CODGEO) and code in np.array(rev15.CODGEO):\n",
        "        return (rev14.MED[rev14.CODGEO==code].values[0] + \n",
        "                rev15.MED[rev15.CODGEO==code].values[0] ) / 2\n",
        "    else:\n",
        "        revdep14, revdep15 = revenus_dep[2], revenus_dep[3]\n",
        "        return (revdep14.MED[revdep14.CODGEO==code[:2]].values[0] + \n",
        "                revdep15.MED[revdep15.CODGEO==code[:2]].values[0] ) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-q1OuArx5L3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Puis on écrit la fonction qui renvoie la colonne des revenus médians, en discriminant suivant si le code Insee est présent dnas la liste des codes Insee des données \"revenus\". Dans le cas où le code Insee n'existe pas (c'est le cas pour une soixantaine de lignes), on prend le revenu médian du département :"
      ]
    },
    {
      "metadata": {
        "id": "HWhX3m8Uoj6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ajout_revenu(X, revenus, revenus_dep):\n",
        "    \"\"\"Renvoie la colonne contenant le revenu médian pour les années où l'on \n",
        "    dispose des données, et une prédiction de ce revenu pour les autres années\"\"\"\n",
        "    codes = [np.array(revenus[annee-2012].CODGEO) for annee in range(2012,2016)]\n",
        "    n = len(X)\n",
        "    rev_med = np.zeros(n)\n",
        "    for k in range(n):\n",
        "        annee = int(X.ft_2_categ[k])\n",
        "        if is_nan(X.Insee[k]):\n",
        "            rev_med[k] = -1\n",
        "        elif annee == 2016:\n",
        "            rev_med[k] = pred_revenu_2016(X.Insee[k], revenus, revenus_dep)\n",
        "        elif X.Insee[k] not in codes[annee-2012]:\n",
        "            rev_med[k] = revenus_dep[annee-2012].MED[revenus_dep[annee-2012].CODGEO==X.Insee[k][:2]]\n",
        "        else:\n",
        "            rev_med[k] = revenus[annee-2012].MED[revenus[annee-2012].CODGEO==X.Insee[k]]\n",
        "     \n",
        "    #On remplace les valeurs manquantes\n",
        "    rev_med = replace_missing_by_mean(rev_med)\n",
        "\n",
        "    return rev_med"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pLIE9W-PoAcT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Association des données supplémentaires"
      ]
    },
    {
      "metadata": {
        "id": "YiIEnGqCoIVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prep_train(X, y, path):\n",
        "    #Importation des fichiers de données\n",
        "    cat = path +'/catastrophes naturelles/'\n",
        "    crim = path +'criminalité/'\n",
        "    catnat = pd.read_csv(cat+\"catnat_propre.csv\", header=0,sep=';')\n",
        "    crimes = pd.read_excel(crim+\"crimes_propre.xlsx\", header=0,sep=';')\n",
        "    pprn = pd.read_excel(cat+\"pprn_propre.xlsx\", header=0)\n",
        "    pluie = pd.read_excel(cat+\"pluie.xlsx\", header=0)\n",
        "    chomage = pd.read_csv(path+\"chomage/chomage_propre.csv\", header=0, index_col=0)\n",
        "    log_sociaux=pd.read_excel(path+\"log_sociaux.xls\",header=0,sep='')\n",
        "    revenus = [] #Liste de DataFrames\n",
        "    revenus_dep = [] #Revenus par départements\n",
        "    for annee in range(2012,2016):\n",
        "        revenus.append(pd.read_csv(path+\"revenus/revenus_%s_propre.csv\"%(annee), header=0, index_col=0))\n",
        "        revenus_dep.append(pd.read_csv(path+\"revenus/revenus_%s_dep_propre.csv\"%(annee), header=0, index_col=0))\n",
        "\n",
        "    ##On supprime les NaN (hors ft_22_categ), on réindexe X et on sauvegarde les indices supprimés\n",
        "    X = X.dropna(axis=0, subset=['superficief', 'Insee'])\n",
        "    indices = X.index.values\n",
        "    X.index = range(len(X))\n",
        "    \n",
        "    #On supprime les mêmes éléments dans y\n",
        "    y = y.loc[indices,:]\n",
        "  \n",
        "    X_ajout = X.copy()\n",
        "    Catnat = []\n",
        "    Crim = []\n",
        "    Cpprn = []\n",
        "    Cpluie = []\n",
        "    Cft22 = []\n",
        "    Clog_sociaux=[]\n",
        "    \n",
        "    ##Parcours des lignes pour crimes et catastrophes naturelles\n",
        "    for x in X_ajout.itertuples():\n",
        "    \n",
        "        ##Données sur le nombre de jour de catastrophes naturelles\n",
        "        a=catnat[x.Insee==catnat.Insee]\n",
        "        a=a[x.ft_2_categ==a.annee]\n",
        "        ##On somme les différents arrêtés simulatannés pour la même zone\n",
        "        Catnat+=[a.num_risque_jo.sum()]\n",
        "    \n",
        "        ##Données sur les PPRN\n",
        "        a=pprn[x.Insee[:2]==pprn.cod_commune]\n",
        "        a=a[x.ft_2_categ==a.dat_mise_a_enquete_deb]\n",
        "        Cpprn+=[len(a)]\n",
        "    \n",
        "        ##Données sur le nombre de jour avec plus de 1m de précipitation\n",
        "        a=pluie[x.Insee[:2]==pluie.departement]\n",
        "        Cpluie+=[a[x.ft_2_categ].iloc[0]]\n",
        "    \n",
        "        ##Données sur le taux de criminalité\n",
        "        a=crimes[x.Insee[:2]==crimes.departement]\n",
        "        a=a[x.ft_2_categ==a.annee]\n",
        "        Crim+=[a.criminalite.iloc[0]]\n",
        "        \n",
        "        #Données manquantes de ft_22_categ\n",
        "        if is_nan(x.ft_22_categ):\n",
        "            Cft22 += [-1]\n",
        "        else:\n",
        "            Cft22 += [x.ft_22_categ]\n",
        "            \n",
        "        #Données sur le logement sociaux\n",
        "        a=log_sociaux[x.Insee[:2]==log_sociaux.Dep]\n",
        "        Clog_sociaux+=[a.Nb_log_sociaux.iloc[0]]\n",
        "        \n",
        "    ##Chomage\n",
        "    Cchomage = ajout_chomage(X_ajout, chomage)\n",
        "    \n",
        "    ##Revenus\n",
        "    Crevenus = ajout_revenu(X, revenus, revenus_dep)\n",
        "    \n",
        "    #Ajout des colonnes dans le DataFrame\n",
        "    X_ajout['pluie'] = Cpluie\n",
        "    X_ajout['catnat'] = Catnat\n",
        "    X_ajout['criminalite'] = Crim\n",
        "    X_ajout['pprn'] = Cpprn\n",
        "    X_ajout['chomage'] = Cchomage\n",
        "    X_ajout['rev_med'] = Crevenus\n",
        "    X_ajout['ft_22_categ'] = Cft22\n",
        "    X_ajout['log_sociaux']=Clog_sociaux\n",
        "            \n",
        "    return(X_ajout, y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odRoxrJqJYmZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prep_test(X, path):\n",
        "    #Importation des fichiers de données\n",
        "    cat = path +'/catastrophes naturelles/'\n",
        "    crim = path +'criminalité/'\n",
        "    catnat = pd.read_csv(cat+\"catnat_propre.csv\", header=0,sep=';')\n",
        "    crimes = pd.read_excel(crim+\"crimes_propre.xlsx\", header=0,sep=';')\n",
        "    pprn = pd.read_excel(cat+\"pprn_propre.xlsx\", header=0)\n",
        "    pluie = pd.read_excel(cat+\"pluie.xlsx\", header=0)\n",
        "    chomage = pd.read_csv(path+\"chomage/chomage_propre.csv\", header=0, index_col=0)\n",
        "    log_sociaux=pd.read_excel(path+\"log_sociaux.xls\",header=0,sep='')\n",
        "    revenus = [] #Liste de DataFrames\n",
        "    revenus_dep = [] #Revenus par départements\n",
        "    for annee in range(2012,2016):\n",
        "        revenus.append(pd.read_csv(path+\"revenus/revenus_%s_propre.csv\"%(annee), header=0, index_col=0))\n",
        "        revenus_dep.append(pd.read_csv(path+\"revenus/revenus_%s_dep_propre.csv\"%(annee), header=0, index_col=0))\n",
        "\n",
        "  \n",
        "    X_ajout = X.copy()\n",
        "    Catnat = []\n",
        "    Crim = []\n",
        "    Cpprn = []\n",
        "    Cpluie = []\n",
        "    Csuperficie = []\n",
        "    Cft22 = []\n",
        "    Clog_sociaux = []\n",
        "    \n",
        "    ##Parcours des lignes pour crimes et catastrophes naturelles\n",
        "    for x in X_ajout.itertuples():\n",
        "    \n",
        "        ##Données sur le nombre de jour de catastrophes naturelles\n",
        "        if not is_nan(x.Insee):\n",
        "            a=catnat[x.Insee==catnat.Insee]\n",
        "            a=a[x.ft_2_categ==a.annee]\n",
        "            ##On somme les différents arrêtés simulatannés pour la même zone\n",
        "            Catnat+=[a.num_risque_jo.sum()]\n",
        "        else:\n",
        "            Catnat+=[-1]\n",
        "    \n",
        "        ##Données sur les PPRN\n",
        "        if not is_nan(x.Insee):\n",
        "            a=pprn[x.Insee[:2]==pprn.cod_commune]\n",
        "            a=a[x.ft_2_categ==a.dat_mise_a_enquete_deb]\n",
        "            Cpprn+=[len(a)]\n",
        "        else:\n",
        "            Cpprn+=[-1]\n",
        "    \n",
        "        ##Données sur le nombre de jour avec plus de 1m de précipitation\n",
        "        if not is_nan(x.Insee):\n",
        "            a=pluie[x.Insee[:2]==pluie.departement]\n",
        "            Cpluie+=[a[x.ft_2_categ].iloc[0]]\n",
        "        else:\n",
        "            Cpluie+=[-1]\n",
        "    \n",
        "        ##Données sur le taux de criminalité\n",
        "        if not is_nan(x.Insee):\n",
        "            a=crimes[x.Insee[:2]==crimes.departement]\n",
        "            a=a[x.ft_2_categ==a.annee]\n",
        "            Crim+=[a.criminalite.iloc[0]]\n",
        "        else:\n",
        "            Crim+=[-1]\n",
        "            \n",
        "        #Données manquantes sur superficief\n",
        "        if is_nan(x.superficief):\n",
        "            Csuperficie += [-1]\n",
        "        else:\n",
        "            Csuperficie += [x.superficief]\n",
        "            \n",
        "        #Données manquantes de ft_22_categ\n",
        "        if is_nan(x.ft_22_categ):\n",
        "            Cft22 += [-1]\n",
        "        else:\n",
        "            Cft22 += [x.ft_22_categ]\n",
        "                    \n",
        "        #Données sur le logement sociaux\n",
        "        if not is_nan(x.Insee):\n",
        "            a=log_sociaux[x.Insee[:2]==log_sociaux.Dep]\n",
        "            Clog_sociaux+=[a.Nb_log_sociaux.iloc[0]]\n",
        "        else:\n",
        "            Clog_sociaux+=[np.mean(log_sociaux.Nb_log_sociaux)]\n",
        "            \n",
        "    ##Chomage\n",
        "    Cchomage = ajout_chomage(X_ajout, chomage)\n",
        "    \n",
        "    ##Revenus\n",
        "    Crevenus = ajout_revenu(X, revenus, revenus_dep)\n",
        "    \n",
        "    #Ajout des valeurs manquantes\n",
        "    Catnat = replace_missing_by_med(np.array(Catnat))\n",
        "    Cpprn = replace_missing_by_med(np.array(Cpprn))\n",
        "    Cpluie = replace_missing_by_mean(np.array(Cpluie))\n",
        "    Crim = replace_missing_by_mean(np.array(Crim))\n",
        "    X_ajout['superficief'] = replace_missing_by_mean(np.array(Csuperficie))\n",
        "    \n",
        "    #Ajout des colonnes dans le DataFrame\n",
        "    X_ajout['pluie'] = Cpluie\n",
        "    X_ajout['catnat'] = Catnat\n",
        "    X_ajout['criminalite'] = Crim\n",
        "    X_ajout['pprn'] = Cpprn\n",
        "    X_ajout['chomage'] = Cchomage\n",
        "    X_ajout['rev_med'] = Crevenus\n",
        "    X_ajout['ft_22_categ'] = Cft22\n",
        "    X_ajout['log_sociaux']=Clog_sociaux\n",
        "            \n",
        "    return X_ajout\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tKepxAo12p2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Création du nouveau fichier"
      ]
    },
    {
      "metadata": {
        "id": "nr7WjLviuZ9H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sauvegarde du fichier :"
      ]
    },
    {
      "metadata": {
        "id": "FVgXQ4A1Jpon",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mypath = \"/Users/Benjamin/Documents/MATHAPPLI/APST-ML/DataChallenge/DataChallengeGenerali/data/\"\n",
        "#mypath= \"C:/Users/Asus/Documents/Cours/EI2/APST/Generali/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdNwUKxuubn_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_new_data, y_train_new_data = prep_train(X_train, y_train, mypath)\n",
        "X_train_new_data.to_csv(mypath+'X_train_new_data.csv')\n",
        "y_train_new_data.to_csv(mypath+'y_train_saegPGl_new_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbE8tYg9eOVL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_new_data = prep_test(X_test, mypath)\n",
        "X_test_new_data.to_csv(mypath+'X_test_new_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtuKjv_kzTpz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}